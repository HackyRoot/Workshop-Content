{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HackyRoot/Workshop-Content/blob/master/Footprints_2019/6%20-%20TensorFlow%20and%20Keras/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "F3WBuOLbAC2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfbwpagoAJiV",
        "colab_type": "code",
        "outputId": "074f736d-5ec5-4edc-d00e-23e255e13273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t0Q0F8LXALM3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inputs and Outputs\n",
        "\n",
        "So, in this next step, we're just going to create a session. Your x and y_ are just going to place placeholders that basically just indicate the type of input you want in your CNN and the type of output. For each of these placeholders, you have to specify the type and the shape."
      ]
    },
    {
      "metadata": {
        "id": "-EzoilR2APx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6c23dc95-4b82-4bb6-fea2-4f6fb542ea3b"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph() \n",
        "sess = tf.InteractiveSession()\n",
        "x = tf.placeholder(\"float\", shape = [None, 28,28,1]) #shape in CNNs is always None x height x width x color channels\n",
        "y_ = tf.placeholder(\"float\", shape = [None, 10]) #shape is always None x number of classes"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9_98etOrATbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network Architecture\n",
        "Now that we have our placeholders, we just have to specify the network architecture. Basically, the main point we have to remember is that all of the filters (weights) and biases are tensorflow variables. Let's create our filter and bias for the first layer\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ELVY3NIBAXSU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))#shape is filter x filter x input channels x output channels\n",
        "b_conv1 = tf.Variable(tf.constant(.1, shape = [32])) #shape of the bias just has to match output channels of the filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgD_yGB4AaSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have our filter and our bias, we can call our first conv layer. The 4 arguments you have to specify are the input (which is where our placeholder comes into play), the filter (we just created the variable for that), the stride, and the padding\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rm69XZGsAb-e",
        "colab_type": "code",
        "outputId": "062177c8-ba06-4290-8591-45ab5148d6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "print (x)\n",
        "print (W_conv1)\n",
        "h_conv1 = tf.nn.conv2d(input=x, filter=W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
        "h_conv1 = tf.nn.relu(h_conv1)\n",
        "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "<tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OpVBg4G0Aet2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvqG9UGeAhAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will complete the whole network adding some more layers"
      ]
    },
    {
      "metadata": {
        "id": "k_01aIlIAlZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Second Conv and Pool Layers\n",
        "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
        "b_conv2 = tf.Variable(tf.constant(.1, shape = [64]))\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)\n",
        "\n",
        "#First Fully Connected Layer\n",
        "W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))\n",
        "b_fc1 = tf.Variable(tf.constant(.1, shape = [1024]))\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "#Dropout Layer\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "#Second Fully Connected Layer\n",
        "W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))\n",
        "b_fc2 = tf.Variable(tf.constant(.1, shape = [10]))\n",
        "\n",
        "#Final Layer\n",
        "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ftfbtYYMApco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will formulate our loss function and then try to minimise it by an optimizer"
      ]
    },
    {
      "metadata": {
        "id": "WC_ozk2WAnuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crossEntropyLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGOQDd58Ayfx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainStep = tf.train.AdamOptimizer().minimize(crossEntropyLoss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2kAyNdoA0Ix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Steps for calculating accuracy\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Zjl546XA6W-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next line is the main statement that gets initializes all the variables we've declared earlier\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Fzi6nZQrA8Wg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcP5rP3VA-Eg",
        "colab_type": "code",
        "outputId": "410eb6f3-96e5-4d98-c8c8-66bf4ba2e9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tf.summary.scalar('Cross Enropy Loss', crossEntropyLoss)\n",
        "tf.summary.scalar('Accuracy', accuracy)\n",
        "merged = tf.summary.merge_all()\n",
        "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "writer = tf.summary.FileWriter(logdir, sess.graph)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name Cross Enropy Loss is illegal; using Cross_Enropy_Loss instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nBCpLIFLBBYi",
        "colab_type": "code",
        "outputId": "b357494f-faf7-4842-9b1f-8bd1b0e03d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "b = mnist.train.next_batch(1)\n",
        "print (b[0].shape) #b[0] contains the image \n",
        "image = tf.reshape(b[0], [-1,28,28,1])\n",
        "print (image)\n",
        "my_img = image.eval() #here is your image Tensor\n",
        "my_i = my_img.squeeze()\n",
        "plt.imshow(my_i, cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 784)\n",
            "Tensor(\"Reshape_1:0\", shape=(1, 28, 28, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQdVNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "94hCdy0CBDpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training\n"
      ]
    },
    {
      "metadata": {
        "id": "oUhxV3xuBGzO",
        "colab_type": "code",
        "outputId": "fa345706-5fbf-4252-ce53-8e4f5875464a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "batchSize = 50\n",
        "for i in range(1000):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    trainingInputs = batch[0].reshape([batchSize,28,28,1])\n",
        "    trainingLabels = batch[1]\n",
        "    if i%10 == 0:\n",
        "        summary = sess.run(merged, {x: trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
        "        writer.add_summary(summary, i)\n",
        "    if i%100 == 0:\n",
        "        trainAccuracy = accuracy.eval(session=sess, feed_dict={x:trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
        "        print (\"step %d, training accuracy %g\"%(i, trainAccuracy))\n",
        "    trainStep.run(session=sess, feed_dict={x: trainingInputs, y_: trainingLabels, keep_prob: 0.5})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 300, training accuracy 0.98\n",
            "step 400, training accuracy 0.98\n",
            "step 500, training accuracy 1\n",
            "step 600, training accuracy 0.98\n",
            "step 700, training accuracy 0.98\n",
            "step 800, training accuracy 1\n",
            "step 900, training accuracy 0.98\n",
            "step 0, training accuracy 0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Md6l5f0sBKZy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "H8E4VbHvBLmL",
        "colab_type": "code",
        "outputId": "762c9f2a-20e2-41bb-92e0-139c1c25c714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "testInputs = mnist.test.images.reshape([-1, 28, 28, 1])\n",
        "testLabels = mnist.test.labels\n",
        "acc = accuracy.eval(feed_dict = {x: testInputs, y_: testLabels, keep_prob: 1.0})\n",
        "print(\"testing accuracy: {}\".format(acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing accuracy: 0.982200026512146\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}